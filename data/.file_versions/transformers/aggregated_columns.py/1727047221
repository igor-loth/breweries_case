import pandas as pd
import os
import pyarrow as pa
import pyarrow.parquet as pq

if 'transformer' not in globals():
    from mage_ai.data_preparation.decorators import transformer


@transformer
def transform_data(*args, **kwargs):
    # Caminho dos dados da camada Silver
    silver_data_dir = './data/silver/breweries/'
    
    # Verificar se o diretório existe
    if not os.path.exists(silver_data_dir):
        raise FileNotFoundError(f"O diretório {silver_data_dir} não foi encontrado.")
    
    # Carregar todos os arquivos Parquet da camada Silver
    dataframes = []
    for root, dirs, files in os.walk(silver_data_dir):
        for file in files:
            if file.endswith('.parquet'):
                file_path = os.path.join(root, file)
                df = pd.read_parquet(file_path)
                dataframes.append(df)
    
    # Concatenar todos os dataframes em um único dataframe
    if len(dataframes) == 0:
        raise ValueError("Nenhum arquivo Parquet foi encontrado na camada Silver.")
    
    df = pd.concat(dataframes)

    # Verificar se as colunas necessárias existem
    if 'state' not in df.columns or 'brewery_type' not in df.columns:
        raise ValueError("As colunas 'state' ou 'brewery_type' não foram encontradas nos dados.")
    
    # Realizar a agregação para contar o número de cervejarias por tipo e localização (state)
    aggregated_df = df.groupby(['state', 'brewery_type']).size().reset_index(name='brewery_count')

    # Criar diretório para dados Gold
    gold_data_dir = './data/gold/breweries/state_brewery_type/'
    os.makedirs(gold_data_dir, exist_ok=True)

    # Salvar o resultado como Parquet
    gold_file_path = os.path.join(gold_data_dir, 'breweries_aggregated.parquet')
    table = pa.Table.from_pandas(aggregated_df)
    pq.write_table(table, gold_file_path)

    print(f'Dados agregados salvos em: {gold_file_path}')


if __name__ == "__main__":
    transform_data()
