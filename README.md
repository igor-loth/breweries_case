# breweries case(Data Pipeline)

### IntroduÃ§Ã£o
O objetivo desse projeto Ã© criar um pipeline consumindo dados de um API e armazenando em um ambiente Data Lake seguindo a arquitetura Medallion com trÃªs camadas:
- **Bronze ğŸŸ¤:** Dados Brutos.
- **Silver âšª:** Dados selecionados e particionado por localizaÃ§Ã£o.
- **Gold ğŸŸ¡:** Dados agredados para anÃ¡lise.
- **Extra ğŸ“Š:** VisualizaÃ§Ã£o grÃ¡fica dos dados que estÃ£o na camada Gold.

### Feramentas utilizadas 
- **Python** - Linguagem escolhida para a extraÃ§Ã£o e tratamento dos dados entre as camadas do nosso Data Lake.
- **Mage** - Orquestrador do nosso ambiente, nele podemos ter uma visÃ£o macro do nosso pipeline e trabalhar com blocos (data loader, transform, data exporter).
- **MinIO** - RepositÃ³rio de dados (Tem o mesmo conceito que o AWS S3). Nele vamos criar nossas camadas do Data Lake que armazenarÃ£o os dados.
- **Docker** - ConteinerizaÃ§Ã£o do nosso ambiente, configurado em um *docker-compose.yml*.

## Arquitetura
