# breweries case(Data Pipeline)

### Introdu√ß√£o
O objetivo desse projeto √© criar um pipeline consumindo dados de um API armazenando em um ambiente Data Lake seguindo a arquitetura Medallion com tr√™s camadas:
- **Bronze üü§:** Dados Brutos.
- **Silver ‚ö™:** Dados selecionados e particionado por localiza√ß√£o.
- **Gold üü°:** Dados agredados para an√°lise.
- **Extra üìä:** Visualiza√ß√£o gr√°fica dos dados que est√£o na camada Gold.

### Feramentas utilizadas 
- **Python** - Linguagem escolhida para a extra√ß√£o e tratamento dos dados entre as camadas do nosso Data Lake.
- **Mage** - Orquestrador do nosso ambiente, nele podemos ter uma vis√£o macro do nosso pipeline e trabalhar com blocos (data loader, transform, data exporter).
- **MinIO** - Reposit√≥rio de dados (Tem o mesmo conceito que o AWS S3). Nele vamos criar nossas camadas do Data Lake que armazenar√£o os dados.
- **Docker** - Conteineriza√ß√£o do nosso ambiente, configurado em um *docker-compose.yml*.

## Arquitetura
![GET](image/arquitetura.png)

## Pr√© Work
Caso queira ver o Pipeline funcionando, antes de clonar o reposit√≥rio, tem algumas etapas de configura√ß√£o: 
- Instalar Docker (Estou utilizando no linux).
- Instalar Python (Python 3.10.12 or more).
- Criar um arquivo *.env* para incluir as chaves de acesso do MinIO, evitando expor usu√°rio e senha no c√≥digo-fonte:
  ```bash
      # Definir o nome do usu√°rio e senha que precisa conectar no servi√ßo Web
      MINIO_ACCESS_KEY='<USER>'
      MINIO_SECRET_KEY='<SENHA>'
  ```
- Subir o ambiente:
  ```bash
      # Construir as imagens 
      docker-compose build

      # Subir o ambiente
      docker-compose up -d
  ```
- Acessar o Mage: ```http://localhost:6789/```
- Acessar o MinIO: ```http://localhost:9001/```

## Orquestra√ß√£o - Mage
Toda orquestra√ß√£o entre as camadas, desde o load at√© a vis√£o agregada dos dados na camada Gold + a constru√ß√£o do gr√°fico est√° centralizada no Mage. Nele podemos visualizar a √°rvore dos blocos que utilizamos para o tratamento dos dados. Al√©m de executar blocos espec√≠ficos ou o pipeline todo.

 ![GET](image/main_mage.png)
 
üå≥ √Årvore dos blocos üå≥:

![GET](image/tree_orquestracao.png)

## Extra√ß√£o - Bronze
Para a extra√ß√£o, foi criado um script python utilizando o bloco Data Loader do Mage [extract_breweries_data.py](data/data_loaders/extract_breweries_data.py) no qual captura os dados da API e armazena na camada Bronze no MinIO. O script salva os dados em um arquivo JSON ```breweries_raw.json``` na parti√ß√£o ```bronze/data/breweries/```. Caso o bucket n√£o tenha sido criado, o pr√≥prio script faz a cria√ß√£o:

![GET](image/bronze.png)

## Transforma√ß√£o - Silver
O pr√≥ximo passo √© capturar os dados brutos que est√£o na camada Bronze, particion√°-los por localiza√ß√£o das cervejarias e salvar o resultado na camada Silver ```silver/data/breweries/<location>``` em um formato de armazenamento colunar. No caso utilizaremos o parquet, visando melhor economia no armazenamento, OLAP e desempenho dos dados.

O script [transform_breweries.py](data/transformers/transform_breweries.py) est√° utilizando o bloco Transformer do Mage

![GET](image/silver.png)

Aqui est√° um exemplo de como fica o arquivo nesta camada:

![GET](image/silver_file.png)


## Transforma√ß√£o - Gold
Por fim, o script [aggregated_columns.py](data/transformers/aggregated_columns.py) utilizando o bloco Transformer do Mage, pega os dados da camada Silver, valida se h√° os arquivos dentro das parti√ß√µes e se existe as colunas necess√°rias para criar uma vis√£o agregada com a quantidade de cervejarias por tipo e localiza√ß√£o. Salvando os dados na parti√ß√£o ```gold/data/state_brewery_type/``` no seguinte arquivo ```breweries_aggregated.parquet```.

![GET](image/gold.png)


## Disponibiliza√ß√£o - Data viz
**Extra** - O pipeline conta com um bloco Data Exporte do Mage que cont√©m o script [data_viz.py](data/data_exporters/data_viz.py), no qual captura o resultado da agrega√ß√£o na camada Gold e cria um gr√°fico utilizando as bibliotecas ```pyplot``` e ```seaborn```. O gr√°fico √© armazenado tanto na camada Gold, mais precisamente na parti√ß√£o ```gold/data/visualizations```, como tamb√©m salva em um diret√≥rio local ```./data/visualizations/breweries_aggregated.png```.

![GET](image/visualization.png)

üìä Output do gr√°fico üìä:

![GET](image/grafico.png)


## Logs
Caso ocorra algum erro no processo, os logs s√£o armazenados tamb√©m no bucket, mais precisamente na parti√ß√£o ```<camada>/logs```. Todas as camadas (Bronze, Silver e Gold) seguem o mesmo padr√£o.

![GET](image/log.png)

![GET](image/exe_log.png)

## Monitoramento e Disponibilidade - Pr√≥ximos Passos
Como um upgrade para este pipeline, podemos aproveitar os logs de erro (caso tenha) das etapas de extra√ß√£o e tratamento de dados, para criar um ambiente de monitoramento e disponibilidade dos dados.

Para isso, apresento algumas solu√ß√µes:
-  **Zabbix** -  Aproveitar a liberdade que esta ferramenta tem de personalizar monitoramentos, criando triggers que captura o output dos logs das camadas. O monitoramento, por exemplo, pode gerar um alerta cr√≠tico replicando para algum servi√ßo de mensageria (Telefone, Email, SMS, Slack e etc...)
- **Prometheus + Grafana** - Criar m√©tricas personalizadas, configurando Prometheus para coletar dados de uso e performance diretamente das APIs MinIO (Ou APIs S3) e usar o Grafana para visualiza√ß√µes detalhadas, oferecendo uma vis√£o clara das atividades nas camadas Bronze, Silver, e Gold.



